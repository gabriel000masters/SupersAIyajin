{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "'''\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Resize((224, 224)),\n",
    "            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
    "            iaa.Sometimes(0.25,\n",
    "                          iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                     iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
    "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "        '''\n",
    "\n",
    "class SsjDataset(Dataset):\n",
    "    def __init__(self, archivocsv):\n",
    "        self.arch_csv = pd.read_csv(archivocsv, engine='python', delimiter=';')\n",
    "        self.ruta_imagenes = np.asarray(self.arch_csv.iloc[:, 0])\n",
    "        self.arr_labels = np.asarray(self.arch_csv.iloc[:, 1])\n",
    "        self.largo_datos = len(self.arch_csv.index)\n",
    "        self.transformar = transformada = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.arch_csv)\n",
    "\n",
    "    def __getitem__(self, indice):\n",
    "        nom_imagen = self.ruta_imagenes[indice]\n",
    "        imagen = Image.open(nom_imagen)\n",
    "        label_salida = self.arr_labels[indice]\n",
    "        imagen = self.transformar(imagen)\n",
    "\n",
    "\n",
    "\n",
    "        return imagen, label_salida\n",
    "\n",
    "\n",
    "dataset = SsjDataset(\"Dataset_git.csv\")\n",
    "print(len(dataset))\n",
    "tam_ent = int(0.6 * len(dataset))\n",
    "tam_pru = len(dataset) - tam_ent\n",
    "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "set_ent, set_pru = torch.utils.data.random_split(dataset, [tam_ent, tam_pru])\n",
    "dl_ent = DataLoader(set_ent, batch_size=16, shuffle=True)\n",
    "dl_pru = DataLoader(set_pru, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "class Red(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Red, self).__init__()\n",
    "        self.ent_conv1 = nn.Conv2d(3, 8, 5)\n",
    "        self.conv1_conv2 = nn.Conv2d(8,12, 5)\n",
    "        self.conv2_lineal1 = nn.Linear(12*5*5, 84)\n",
    "        self.lineal1_lineal2 = nn.Linear(84, 84)\n",
    "        self.lineal2_salida = nn.Linear(84, 3)\n",
    "        self.pooling2d = torch.nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 3, 1, 2)\n",
    "        x = self.pooling2d(F.relu(self.ent_conv1(x.float())))\n",
    "        x = self.pooling2d(F.relu(self.conv1_conv2(x)))\n",
    "        x = x.view(x.size(0), 12*5*5)\n",
    "        x = F.relu(self.conv2_lineal1(x))\n",
    "        x = F.relu(self.lineal1._lineal2(x))\n",
    "        x = self.lineal2_salida(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "modelo = models.resnet18(pretrained=True)\n",
    "for param in modelo.parameters():\n",
    "  param.requires_grad = False\n",
    "ent_modelo = modelo.fc.in_features\n",
    "modelo.fc = nn.Linear(ent_modelo, 3)\n",
    "print(modelo)\n",
    "modelo = modelo.to(dispositivo)\n",
    "func_error = nn.CrossEntropyLoss()\n",
    "optimizador = optim.SGD(modelo.parameters(), lr=0.001, momentum=0.9)\n",
    "epocas = 20\n",
    "error_acumulado = 0.0\n",
    "modelo.train()\n",
    "\n",
    "for epoca in range(epocas):\n",
    "    for indice, datos in enumerate(dl_ent, 0):\n",
    "        entradas, objetivos = datos\n",
    "        entradas, objetivos = entradas.to(dispositivo), objetivos.to(dispositivo)\n",
    "        optimizador.zero_grad()\n",
    "        salidas = modelo(entradas)\n",
    "        error = func_error(salidas, objetivos)\n",
    "        error.backward()\n",
    "        optimizador.step()\n",
    "        error_acumulado += error.item()\n",
    "        if indice % 7 == 3:  # print every 2000 mini-batches\n",
    "            print('[%d, %5d] error: %.3f' %\n",
    "            (epoca + 1, indice + 1, error_acumulado / 2000))\n",
    "            error_acumulado = 0.0\n",
    "\n",
    "\n",
    "\n",
    "torch.save(modelo.state_dict(), \"SSJ_entrenado.pth\")\n",
    "print(\"Modelo entrenado y guardado\")\n",
    "\n",
    "correctas=0\n",
    "totales=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelo.eval()\n",
    "    for datos in dl_pru:\n",
    "        entradas, objetivos = datos\n",
    "        entradas, objetivos = entradas.to(dispositivo), objetivos.to(dispositivo)\n",
    "        salidas = modelo(entradas)\n",
    "        _,prediccion = torch.max(salidas.data, 1)\n",
    "        totales += objetivos.size(0)\n",
    "        correctas += (prediccion == objetivos).sum().item()\n",
    "print(\"Presici√≥n del modelo: \",100 * float(correctas / totales),\"%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "csharp"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
